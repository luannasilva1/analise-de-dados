# ğŸ’§ AnÃ¡lise de Consumo de Ãgua e InadimplÃªncia com Databricks ğŸ“Š (Projeto UniversitÃ¡rio - Equipe Databricks & NTT Data)

<p align="left">
  <img src="https://img.shields.io/badge/Databricks-E64627?style=for-the-badge&logo=databricks&logoColor=white" alt="Databricks"/>
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/Apache%20Spark-E64627?style=for-the-badge&logo=apachespark&logoColor=white" alt="Apache Spark"/>
  <img src="https://img.shields.io/badge/SQL-005C84?style=for-the-badge&logo=postgresql&logoColor=white" alt="SQL"/>
  </p>

Bem-vindo ao repositÃ³rio do nosso projeto de anÃ¡lise de dados focado no **consumo de Ã¡gua e no corte do serviÃ§o para clientes**! ğŸ“‰ Este trabalho foi desenvolvido utilizando o poder do **Databricks** para processar e analisar os dados, como parte das nossas atividades acadÃªmicas.

## ğŸ¯ Nosso Desafio

Este repositÃ³rio contÃ©m uma **anÃ¡lise exploratÃ³ria de dados** sobre consumo de Ã¡gua e inadimplÃªncia de clientes. O objetivo principal do projeto foi **identificar padrÃµes de comportamento** com base em informaÃ§Ãµes cruciais como:

* Consumo por mÂ³ ğŸ’§
* Valor da conta ğŸ’°
* Atraso no pagamento â³
* Status de corte do fornecimento âœ‚ï¸

Buscamos entender melhor os fatores que levam Ã  inadimplÃªncia e como o consumo se correlaciona com diferentes perfis de clientes.

---

## ğŸ› ï¸ O Que Fizemos?

Nossa jornada analÃ­tica envolveu:

1.  **Coleta e PreparaÃ§Ã£o dos Dados:** Carregamento e limpeza dos dados para garantir a qualidade da anÃ¡lise.
2.  **AnÃ¡lise ExploratÃ³ria (EDA):** Investigamos os dados para descobrir tendÃªncias, anomalias e relaÃ§Ãµes entre as variÃ¡veis.
3.  **VisualizaÃ§Ã£o de Dados:** Criamos grÃ¡ficos e dashboards para comunicar os insights de forma clara e eficaz. âœ¨
4.  **IdentificaÃ§Ã£o de PadrÃµes:** Focamos em encontrar comportamentos recorrentes e segmentos de clientes com base nos critÃ©rios definidos.

---

## ğŸš€ Tecnologias Utilizadas

* **Databricks:** Plataforma principal para processamento de dados em larga escala e anÃ¡lise colaborativa.
* **Apache Spark:** Motor de processamento por trÃ¡s do Databricks, permitindo anÃ¡lises rÃ¡pidas.
* **Python (com PySpark):** Linguagem de programaÃ§Ã£o para manipulaÃ§Ã£o de dados e criaÃ§Ã£o de scripts de anÃ¡lise.
* **SQL:** Para consultas e manipulaÃ§Ã£o de dados estruturados.
* *(Adicione aqui outras bibliotecas ou ferramentas que vocÃªs usaram, ex: Matplotlib, Seaborn, Pandas)*

---

